{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 377107,
          "sourceType": "datasetVersion",
          "datasetId": 165566
        }
      ],
      "dockerImageVersionId": 30665,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Explainable Brain Tumor Detection",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q grad-cam"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "kmesZIWji2CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib\n",
        "import kornia.augmentation as K\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "matplotlib.style.use('ggplot')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "AcKNRs_Mi2CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For reproducibility\n",
        "seed = 27\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gMjCUVSdi2CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"loading-and-analyzing-the-dataset\" style=\"font-family:verdana;\">\n",
        "    <center>\n",
        "        Loading and Analyzing the Dataset\n",
        "    </center>\n",
        "</h1>"
      ],
      "metadata": {
        "id": "grL38XU1i2CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tumors_path = '/kaggle/input/brain-mri-images-for-brain-tumor-detection/yes/'\n",
        "no_tumors_path = '/kaggle/input/brain-mri-images-for-brain-tumor-detection/no/'"
      ],
      "metadata": {
        "trusted": true,
        "id": "iJX3qSaXi2CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['axes.grid'] = False\n",
        "colors = sns.color_palette('Set1', 2)\n",
        "fig, ax = plt.subplots(2, 5, figsize=(14, 7))\n",
        "ax = ax.flatten()\n",
        "\n",
        "for i in range(5):\n",
        "    image_file = random.choice(os.listdir(tumors_path))\n",
        "    image = Image.open(tumors_path + image_file)\n",
        "    ax[i].imshow(image, cmap='gray')\n",
        "    ax[i].set_title(f'Tumor: {image_file}', color=colors[0], fontsize=10)\n",
        "\n",
        "for i in range(5, 10):\n",
        "    image_file = random.choice(os.listdir(no_tumors_path))\n",
        "    image = Image.open(no_tumors_path + image_file)\n",
        "    ax[i].imshow(image, cmap='gray')\n",
        "    ax[i].set_title(f'No Tumor: {image_file}', color=colors[1], fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "UeIUDW9vi2CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Category': ['Tumor', 'No Tumor'],\n",
        "    'Count': [len(os.listdir(tumors_path)), len(os.listdir(no_tumors_path))]\n",
        "})\n",
        "total = df['Count'].sum()\n",
        "df['Percentage'] = df['Count'] / total * 100\n",
        "\n",
        "ax = sns.barplot(x='Category', y='Count', data=df, palette=colors)\n",
        "legend_labels = [f'{row.Category}: {row.Count} ({row.Percentage:.1f}%)' for _, row in df.iterrows()]\n",
        "patches = [mpatches.Patch(color=colors[i], label=label) for i, label in enumerate(legend_labels)]\n",
        "ax.legend(handles=patches, title_fontsize='13', loc='best')\n",
        "plt.title('Tumor vs No Tumor Distribution', fontsize=15)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "jTpqwKPii2CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"augmentation\" style=\"font-family:verdana;\">\n",
        "    <center>\n",
        "        Augmenting the Images with Kornia\n",
        "    </center>\n",
        "</h1>"
      ],
      "metadata": {
        "id": "ySMbdCjTi2CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_tumors_path = '/kaggle/working/augmented_dataset/yes/'\n",
        "augmented_no_tumors_path = '/kaggle/working/augmented_dataset/no/'\n",
        "\n",
        "try:\n",
        "    os.mkdir('/kaggle/working/augmented_dataset')\n",
        "    os.mkdir('/kaggle/working/augmented_dataset/yes')\n",
        "    os.mkdir('/kaggle/working/augmented_dataset/no')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "trusted": true,
        "id": "oaB92Apdi2CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_augmentations(path: str, augmented_path: str) -> None:\n",
        "    augmentations = [\n",
        "        K.RandomHorizontalFlip(p=1.0),\n",
        "        K.RandomVerticalFlip(p=1.0),\n",
        "        K.RandomRotation(degrees=15, p=1.0),\n",
        "        K.RandomAffine(degrees=15, p=1.0),\n",
        "        K.RandomElasticTransform(p=1.0),\n",
        "        K.RandomGaussianBlur(kernel_size=(5, 9), p=1.0, sigma=(0.1, 5.0)),\n",
        "        K.RandomSharpness(p=1.0),\n",
        "    ]\n",
        "\n",
        "    for image in os.listdir(path):\n",
        "        # Reading the image into PIL format\n",
        "        img = Image.open(path + image).convert('L')\n",
        "\n",
        "        file_extension = image.split('.')[1]\n",
        "        file_name = image.split('.')[0].replace(' ', '-')\n",
        "\n",
        "        # Saving the original image\n",
        "        img.save(f'{augmented_path}{file_name}_Original.{file_extension}')\n",
        "\n",
        "        # Convertering th PIL image to tensor to apply augmentations to it\n",
        "        img = transforms.ToTensor()(img)\n",
        "        for aug in augmentations:\n",
        "            augmented = aug(img)\n",
        "            augmented = augmented.squeeze(0)\n",
        "            augmented = augmented.squeeze(0)\n",
        "\n",
        "            # Convertering the tensor image back to PIL image and saving\n",
        "            augmented = transforms.ToPILImage()(augmented)\n",
        "            augmented.save(f'{augmented_path}{file_name}_{aug.__class__.__name__}.{file_extension}')\n",
        "\n",
        "\n",
        "generate_augmentations(tumors_path, augmented_tumors_path)\n",
        "generate_augmentations(no_tumors_path, augmented_no_tumors_path)\n",
        "\n",
        "print('Original dataset size: ', len(os.listdir(tumors_path)) + len(os.listdir(no_tumors_path)))\n",
        "print('Augmented dataset size: ', len(os.listdir(augmented_tumors_path)) + len(os.listdir(augmented_no_tumors_path)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "VMoeBfmWi2CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'Category': ['Tumor', 'No Tumor'],\n",
        "    'Count': [len(os.listdir(tumors_path)), len(os.listdir(no_tumors_path))]\n",
        "})\n",
        "total = df['Count'].sum()\n",
        "df['Percentage'] = df['Count'] / total * 100\n",
        "\n",
        "df_augmented = pd.DataFrame({\n",
        "    'Category': ['Tumor', 'No Tumor'],\n",
        "    'Count': [len(os.listdir(augmented_tumors_path)), len(os.listdir(augmented_no_tumors_path))]\n",
        "})\n",
        "total_augmented = df_augmented['Count'].sum()\n",
        "df_augmented['Percentage'] = df_augmented['Count'] / total_augmented * 100\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "sns.barplot(x='Category', y='Count', data=df, palette=colors, ax=ax[0])\n",
        "sns.barplot(x='Category', y='Count', data=df_augmented, palette=colors, ax=ax[1])\n",
        "\n",
        "legend_labels = [f'{row.Category}: {row.Count} ({row.Percentage:.1f}%)' for _, row in df.iterrows()]\n",
        "patches = [mpatches.Patch(color=colors[i], label=label) for i, label in enumerate(legend_labels)]\n",
        "ax[0].legend(handles=patches, title_fontsize='13', loc='best')\n",
        "ax[0].set_title('Original Dataset', fontsize=15)\n",
        "\n",
        "legend_labels = [f'{row.Category}: {row.Count} ({row.Percentage:.1f}%)' for _, row in df_augmented.iterrows()]\n",
        "patches = [mpatches.Patch(color=colors[i], label=label) for i, label in enumerate(legend_labels)]\n",
        "ax[1].legend(handles=patches, title_fontsize='13', loc='best')\n",
        "ax[1].set_title('Augmented Dataset', fontsize=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "fb0b_A1Yi2CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    augmented_tumors_path + 'Y100_Original.JPG',\n",
        "    augmented_tumors_path + 'Y100_RandomAffine.JPG',\n",
        "    augmented_tumors_path + 'Y100_RandomElasticTransform.JPG',\n",
        "    augmented_tumors_path + 'Y100_RandomGaussianBlur.JPG',\n",
        "    augmented_tumors_path + 'Y100_RandomHorizontalFlip.JPG',\n",
        "    augmented_tumors_path + 'Y100_RandomRotation.JPG',\n",
        "    augmented_tumors_path + 'Y100_RandomSharpness.JPG',\n",
        "    augmented_tumors_path + 'Y100_RandomVerticalFlip.JPG',\n",
        "]\n",
        "\n",
        "fig, axs = plt.subplots(2, 4, figsize=(12, 7))\n",
        "start_index = 0\n",
        "for row in range(2):\n",
        "    for col in range(4):\n",
        "        filename = Image.open(samples[start_index])\n",
        "        aug_type = filename.filename.split('/')[-1].split('_')[-1].split('.')[0]\n",
        "        axs[row, col].imshow(filename, cmap='gray')\n",
        "        axs[row, col].set_title(aug_type)\n",
        "        axs[row, col].axis('off')\n",
        "        start_index += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "iI5hdioIi2CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"splitting\" style=\"font-family:verdana;\">\n",
        "    <center>\n",
        "        Splitting the Augmented Dataset into Train, Validation, and Test Sets\n",
        "    </center>\n",
        "</h1>"
      ],
      "metadata": {
        "id": "rpij-ItPi2CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_directory(path: str) -> None:\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "\n",
        "\n",
        "def split_data(data: list, train_ratio: float = 0.8, val_ratio: float = 0.1) -> Tuple[list, list, list]:\n",
        "    np.random.shuffle(data)\n",
        "    train_end = int(len(data) * train_ratio)\n",
        "    val_end = int(len(data) * (train_ratio + val_ratio))\n",
        "    return data[:train_end], data[train_end:val_end], data[val_end:]\n",
        "\n",
        "\n",
        "def save_images(data: list, source_dir: str, target_dir: str) -> None:\n",
        "    for filename in data:\n",
        "        img = Image.open(os.path.join(source_dir, filename))\n",
        "        img.save(os.path.join(target_dir, filename))\n",
        "\n",
        "\n",
        "dataset_dirs = [\n",
        "    '/kaggle/working/dataset/train/yes',\n",
        "    '/kaggle/working/dataset/train/no',\n",
        "    '/kaggle/working/dataset/val/yes',\n",
        "    '/kaggle/working/dataset/val/no',\n",
        "    '/kaggle/working/dataset/test/yes',\n",
        "    '/kaggle/working/dataset/test/no'\n",
        "]\n",
        "\n",
        "for dir_path in dataset_dirs:\n",
        "    create_directory(dir_path)\n",
        "\n",
        "tumors = os.listdir(augmented_tumors_path)\n",
        "no_tumors = os.listdir(augmented_no_tumors_path)\n",
        "\n",
        "tumors_train, tumors_val, tumors_test = split_data(tumors)\n",
        "no_tumors_train, no_tumors_val, no_tumors_test = split_data(no_tumors)\n",
        "\n",
        "save_images(tumors_train, augmented_tumors_path, '/kaggle/working/dataset/train/yes')\n",
        "save_images(tumors_val, augmented_tumors_path, '/kaggle/working/dataset/val/yes')\n",
        "save_images(tumors_test, augmented_tumors_path, '/kaggle/working/dataset/test/yes')\n",
        "\n",
        "save_images(no_tumors_train, augmented_no_tumors_path, '/kaggle/working/dataset/train/no')\n",
        "save_images(no_tumors_val, augmented_no_tumors_path, '/kaggle/working/dataset/val/no')\n",
        "save_images(no_tumors_test, augmented_no_tumors_path, '/kaggle/working/dataset/test/no')"
      ],
      "metadata": {
        "trusted": true,
        "id": "iu1iMwpXi2CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"dataloaders\" style=\"font-family:verdana;\">\n",
        "    <center>\n",
        "        Creating Datasets and Dataloaders for Training\n",
        "    </center>\n",
        "</h1>"
      ],
      "metadata": {
        "id": "IZlZKySAi2CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 4\n",
        "DATA_TYPES = ['train', 'val', 'test']\n",
        "\n",
        "data_dir = 'dataset'\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.2470, 0.2470, 0.2470], [0.2364, 0.2364, 0.2364])\n",
        "])\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms) for x in DATA_TYPES}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) for x in DATA_TYPES}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in DATA_TYPES}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "trusted": true,
        "id": "a72PQUL4i2CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        device: str,\n",
        "        model: torch.nn.Module,\n",
        "        criterion: torch.nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        scheduler: torch.optim.lr_scheduler,\n",
        "        train_dataloader: DataLoader,\n",
        "        val_dataloader: DataLoader,\n",
        "        test_dataloader: DataLoader,\n",
        "        checkpoint_path: str\n",
        "    ):\n",
        "        self.device = device\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.best_accuracy = 0.0\n",
        "        self.best_model_path = None\n",
        "\n",
        "    def save_cam_samples(self, model: models.resnet.ResNet, epoch_nr: int) -> None:\n",
        "        samples = [\n",
        "            'samples/Y1.jpg',\n",
        "            'samples/Y2.jpg',\n",
        "            'samples/Y3.jpg',\n",
        "            'samples/Y4.jpg',\n",
        "            'samples/Y6.jpg'\n",
        "        ]\n",
        "\n",
        "        targets = [1, 1, 1, 1, 1]\n",
        "\n",
        "        target_layer = [model.layer4[-1]]\n",
        "        cam = GradCAM(model=model, target_layers=target_layer)\n",
        "\n",
        "        plt.rcParams['axes.grid'] = False\n",
        "\n",
        "        for i, (image_path, target) in enumerate(zip(samples, targets)):\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            image_tensor = transforms.ToTensor()(image).unsqueeze(0)\n",
        "\n",
        "            image = transforms.ToTensor()(image)\n",
        "            image = image.numpy().transpose((1, 2, 0))\n",
        "            image = np.clip(image, 0, 1)\n",
        "\n",
        "            targets = [ClassifierOutputTarget(target)]\n",
        "            grayscale_cam = cam(input_tensor=image_tensor, targets=targets)\n",
        "            grayscale_cam = grayscale_cam[0, :]\n",
        "\n",
        "            visualization = show_cam_on_image(np.array(image_tensor[0].permute(1, 2, 0)), grayscale_cam, use_rgb=True)\n",
        "\n",
        "            filename = image_path.split('/')[-1].split('.')[0]\n",
        "            filetype = image_path.split('/')[-1].split('.')[1]\n",
        "            plt.imshow(visualization)\n",
        "            plt.axis('off')\n",
        "            plt.savefig(f'samples/{filename}-cam-epoch-{epoch_nr}.{filetype}', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "\n",
        "    def train(self, current_epoch_nr: int) -> Tuple[float, float]:\n",
        "        self.model.train()\n",
        "\n",
        "        num_batches = len(self.train_dataloader)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        n_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        if current_epoch_nr == 1:\n",
        "            self.save_cam_samples(self.model, 0)\n",
        "\n",
        "        loop = tqdm(self.train_dataloader, total=num_batches)\n",
        "        for batch in loop:\n",
        "            x, y = batch\n",
        "            x, y = x.to(self.device), y.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            y_hat = self.model(x)\n",
        "            _, preds = torch.max(y_hat, 1)\n",
        "            loss = self.criterion(y_hat, y)\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * x.size(0)\n",
        "            n_corrects += torch.sum(preds == y.data).data.item()\n",
        "            total += y.size(0)\n",
        "\n",
        "            loop.set_description(f'Epoch {current_epoch_nr}')\n",
        "            loop.set_postfix(train_acc=round(n_corrects / total, 5),\n",
        "                             train_loss=round(running_loss / total, 5))\n",
        "\n",
        "        self.scheduler.step()\n",
        "\n",
        "        train_accuracy = n_corrects / total\n",
        "        train_loss = running_loss / num_batches\n",
        "\n",
        "        return train_accuracy, train_loss\n",
        "\n",
        "    def evaluate(self, current_epoch_nr: int) -> Tuple[float, float]:\n",
        "        self.model.eval()\n",
        "\n",
        "        num_batches = len(self.val_dataloader)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        n_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loop = tqdm(self.val_dataloader, total=num_batches)\n",
        "            for batch in loop:\n",
        "                x, y = batch\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                y_hat = self.model(x)\n",
        "                _, preds = torch.max(y_hat, 1)\n",
        "                loss = self.criterion(y_hat, y)\n",
        "\n",
        "                running_loss += loss.item() * x.size(0)\n",
        "                n_corrects += torch.sum(preds == y.data).data.item()\n",
        "                total += y.size(0)\n",
        "\n",
        "\n",
        "                loop.set_description(f'Epoch {current_epoch_nr}')\n",
        "                loop.set_postfix(val_acc=round(n_corrects / total, 5),\n",
        "                                 val_loss=round(running_loss / total, 5))\n",
        "\n",
        "        val_accuracy = n_corrects / total\n",
        "        val_loss = running_loss / num_batches\n",
        "\n",
        "        self.save_cam_samples(self.model, current_epoch_nr)\n",
        "        if val_accuracy > self.best_accuracy:\n",
        "            self.best_accuracy = val_accuracy\n",
        "            checkpoint_name = f'epoch_{current_epoch_nr}_acc_{round(val_accuracy, 2)}.pth'\n",
        "            torch.save(\n",
        "                self.model.state_dict(),\n",
        "                os.path.join(self.checkpoint_path, checkpoint_name)\n",
        "            )\n",
        "            self.best_model_path = os.path.join(self.checkpoint_path, checkpoint_name)\n",
        "\n",
        "        return val_accuracy, val_loss\n",
        "\n",
        "    def test(self) -> Tuple[float, float, list, list, models.resnet.ResNet]:\n",
        "        self.model.eval()\n",
        "\n",
        "        num_batches = len(self.test_dataloader)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        n_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        targets = []\n",
        "        predictions = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loop = tqdm(self.test_dataloader, total=num_batches)\n",
        "            for batch in loop:\n",
        "                x, y = batch\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "\n",
        "                y_hat = self.model(x)\n",
        "                _, preds = torch.max(y_hat, 1)\n",
        "                loss = self.criterion(y_hat, y)\n",
        "\n",
        "                running_loss += loss.item() * x.size(0)\n",
        "                n_corrects += torch.sum(preds == y.data).data.item()\n",
        "                total += y.size(0)\n",
        "\n",
        "                targets.extend(y.cpu().numpy())\n",
        "                predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "                loop.set_description('Testing')\n",
        "                loop.set_postfix(test_acc=round(n_corrects / total, 5),\n",
        "                                 test_loss=round(running_loss / total, 5))\n",
        "\n",
        "        test_accuracy = n_corrects / total\n",
        "        test_loss = running_loss / num_batches\n",
        "\n",
        "        print('\\nTest Accuracy: ', test_accuracy)\n",
        "        print('Test Loss: ', test_loss)\n",
        "\n",
        "        self.model.load_state_dict(torch.load(self.best_model_path))\n",
        "\n",
        "        return test_accuracy, test_loss, targets, predictions, self.model\n",
        "\n",
        "# I will use these samples to visualize CAM results\n",
        "samples = [\n",
        "    tumors_path + 'Y1.jpg',\n",
        "    tumors_path + 'Y2.jpg',\n",
        "    tumors_path + 'Y3.jpg',\n",
        "    tumors_path + 'Y4.jpg',\n",
        "    tumors_path + 'Y6.jpg',\n",
        "]\n",
        "os.makedirs('samples', exist_ok=True)\n",
        "for sample in samples:\n",
        "    img = Image.open(sample)\n",
        "    img.save('samples/' + sample.split('/')[-1])"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "9KIkz7tai2CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"training\" style=\"font-family:verdana;\">\n",
        "    <center>\n",
        "        Training\n",
        "    </center>\n",
        "</h1>"
      ],
      "metadata": {
        "id": "eFtCgJwHi2CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "n_features = model.fc.in_features\n",
        "model.fc = nn.Linear(n_features, len(class_names))\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "mVYy9rdLi2CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 10\n",
        "\n",
        "train_dataloader = dataloaders['train']\n",
        "val_dataloader = dataloaders['val']\n",
        "test_dataloader = dataloaders['test']\n",
        "\n",
        "checkpoint_path = '/kaggle/working/checkpoints'\n",
        "try:\n",
        "    os.mkdir(checkpoint_path)\n",
        "except FileExistsError:\n",
        "    pass\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    device=device,\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    test_dataloader=test_dataloader,\n",
        "    checkpoint_path=checkpoint_path\n",
        ")\n",
        "\n",
        "histories = []\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    train_acc, train_loss = trainer.train(current_epoch_nr=epoch)\n",
        "    val_acc, val_loss = trainer.evaluate(current_epoch_nr=epoch)\n",
        "\n",
        "    histories.append({\n",
        "        'epoch': epoch,\n",
        "        'train_acc': train_acc,\n",
        "        'train_loss': train_loss,\n",
        "        'val_acc': val_acc,\n",
        "        'val_loss': val_loss\n",
        "    })\n",
        "\n",
        "test_acc, test_loss, targets, predictions, best_model = trainer.test()"
      ],
      "metadata": {
        "trusted": true,
        "id": "CxLcG57qi2CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"analyzing-the-results\" style=\"font-family:verdana;\">\n",
        "    <center>\n",
        "        Analyzing the Results\n",
        "    </center>\n",
        "</h1>"
      ],
      "metadata": {
        "id": "haG28Ovpi2CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_accs = [x['train_acc'] for x in histories]\n",
        "train_losses = [x['train_loss'] for x in histories]\n",
        "val_accs = [x['val_acc'] for x in histories]\n",
        "val_losses = [x['val_loss'] for x in histories]\n",
        "\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_accs, label='train', color=colors[0])\n",
        "plt.plot(val_accs, label='val', color=colors[1])\n",
        "plt.axhline(y=test_acc, color='black', linestyle='--', label=f'test: {test_acc:.4f}')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='train', color=colors[0])\n",
        "plt.plot(val_losses, label='val', color=colors[1])\n",
        "plt.axhline(y=test_loss, color='black', linestyle='--', label=f'test: {test_loss:.4f}')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Gg1AqQ1yi2CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(targets, predictions)\n",
        "\n",
        "plt.rcParams['axes.grid'] = False\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Tumor', 'Tumor'], yticklabels=['No Tumor', 'Tumor'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "zinFtAIsi2CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targets, predictions, target_names=['No Tumor', 'Tumor']))"
      ],
      "metadata": {
        "trusted": true,
        "id": "qOgjRbpri2CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 id=\"gradcam\" style=\"font-family:verdana;\">\n",
        "    <center>\n",
        "        Model Explanation with GradCAM\n",
        "    </center>\n",
        "</h1>"
      ],
      "metadata": {
        "id": "l1arqjoWi2CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cam(model: models.resnet.ResNet, image_paths: list, targets: list) -> None:\n",
        "    model = model.eval()\n",
        "\n",
        "    target_layer = [model.layer4[-1]]\n",
        "    cam = GradCAM(model=model, target_layers=target_layer)\n",
        "\n",
        "    plt.rcParams['axes.grid'] = False\n",
        "    fig, axs = plt.subplots(2, 4, figsize=(14, 7))\n",
        "\n",
        "    for i, (image_path, target) in enumerate(zip(image_paths, targets)):\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = transforms.ToTensor()(image)\n",
        "\n",
        "        image_tensor = image.unsqueeze(0)\n",
        "\n",
        "        image = image.numpy().transpose((1, 2, 0))\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "        targets = [ClassifierOutputTarget(target)]\n",
        "        grayscale_cam = cam(input_tensor=image_tensor, targets=targets)\n",
        "        grayscale_cam = grayscale_cam[0, :]\n",
        "\n",
        "        visualization = show_cam_on_image(np.array(image_tensor[0].permute(1, 2, 0)), grayscale_cam, use_rgb=True)\n",
        "\n",
        "        axs[1, i].imshow(image)\n",
        "        axs[1, i].set_title('Original')\n",
        "\n",
        "        axs[0, i].imshow(visualization)\n",
        "        axs[0, i].set_title('Grad-CAM')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "WZlpd3_fi2CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = [os.path.join(tumors_path, filename) for filename in os.listdir(tumors_path)][24:28]\n",
        "plot_cam(best_model, image_paths, [1] * 4)"
      ],
      "metadata": {
        "trusted": true,
        "id": "kxgnVYuji2CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    '/kaggle/working/samples/Y1.jpg',\n",
        "    '/kaggle/working/samples/Y2.jpg',\n",
        "    '/kaggle/working/samples/Y3.jpg',\n",
        "    '/kaggle/working/samples/Y4.jpg',\n",
        "    '/kaggle/working/samples/Y6.jpg'\n",
        "]\n",
        "\n",
        "fig, axs = plt.subplots(len(samples), max_epochs + 2, figsize=(20, 10))\n",
        "start_index = 0\n",
        "for row in range(len(samples)):\n",
        "    filename = Image.open(samples[start_index])\n",
        "    axs[row, 0].imshow(filename, cmap='gray')\n",
        "    axs[row, 0].set_title('Original')\n",
        "    axs[row, 0].axis('off')\n",
        "    start_index += 1\n",
        "\n",
        "    original_filename = filename.filename.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    for col in range(1, max_epochs + 2):\n",
        "        filename = Image.open(f'samples/{original_filename}-cam-epoch-{col-1}.jpg')\n",
        "        axs[row, col].imshow(filename, cmap='gray')\n",
        "        if col == 0:\n",
        "            title = \"Original\"\n",
        "        if col == 1:\n",
        "            title = \"Before Fine-tuning\"\n",
        "        if col > 1:\n",
        "            title = f'Epoch {col - 1}'\n",
        "        axs[row, col].set_title(title)\n",
        "        axs[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "wuZQOkLni2CZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}